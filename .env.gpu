# GPU Environment Variables for RTX 3090 Optimization
# ====================================================

# --- GPU Device Configuration ---
CUDA_VISIBLE_DEVICES=0
CUDA_DEVICE_ORDER=PCI_BUS_ID

# --- PyTorch GPU Optimization ---
PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:512
PYTORCH_CUDA_MEMORY_POOL_ENABLED=1
PYTORCH_ENABLE_MKLDNN=0
PYTORCH_CUDA_ARCH_LIST="8.6"

# --- TensorFlow GPU Optimization ---
TF_GPU_THREAD_MODE=gpu_private
TF_GPU_THREAD_COUNT=2
TF_ENABLE_AUTO_MIXED_PRECISION=1
TF_FORCE_GPU_ALLOW_GROWTH=true
TF_XLA_FLAGS=--tf_xla_auto_jit=2

# --- CUDA Runtime Optimization ---
CUDA_LAUNCH_BLOCKING=0
CUDA_CACHE_PATH=.cuda_cache
CUDA_VISIBLE_DEVICES=0

# --- Memory Management ---
CUDA_MANAGED_FORCE_DEVICE_ALLOC=1
CUDA_MANAGED_MEMORY_POOL_ENABLED=1
CUDA_MALLOC_ASYNC_ENABLED=1

# --- Performance Optimization ---
OMP_NUM_THREADS=8
MKL_NUM_THREADS=8
OPENBLAS_NUM_THREADS=8
NUMEXPR_NUM_THREADS=8
VECLIB_MAXIMUM_THREADS=8

# --- NVIDIA RAPIDS Optimization ---
RAPIDS_NO_INITIALIZE=1
CUPY_CACHE_DIR=.cupy_cache
CUPY_CUDA_MEMORY_POOL_PINNED_POOL_SIZE=2147483648

# --- GPU Monitoring and Debugging ---
NCCL_DEBUG=INFO
NCCL_DEBUG_SUBSYS=INIT
NCCL_SOCKET_IFNAME=^docker0,lo

# --- Mixed Precision Training ---
# Enable TF32 for better performance on Ampere architecture
NVIDIA_TF32_OVERRIDE=1

# --- Memory Allocation Strategy ---
# Conservative allocation for stability
PYTORCH_CUDA_MEMORY_CACHING_ENABLED=1
TF_CPP_MIN_LOG_LEVEL=2

# --- GPU-specific performance flags ---
# Enable kernel fusion and optimization
CUBLAS_WORKSPACE_CONFIG=:16:8
CUBLAS_WORKSPACE_CONFIG=:4096:8

# --- Threading optimization ---
# Limit CPU threads to prevent oversubscription
RAY_DISABLE_IPC=1
RAY_OBJ_STORE_MEMORY_SPAWN_THRESHOLD=1073741824