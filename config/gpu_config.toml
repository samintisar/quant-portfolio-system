# GPU Configuration for RTX 3090
# =====================================
# Configuration file for GPU optimization settings

[gpu]
# GPU device configuration
enabled = true
device = "cuda:0"
primary_device_index = 0

# RTX 3090 specifications
memory_limit_gb = 24
compute_capability = "8.6"
tensor_cores = true

# GPU availability check
auto_detect = true
fallback_to_cpu = false

[gpu.optimization]
# Performance optimization settings
mixed_precision = true
gradient_accumulation = true
memory_efficient_attention = true
automatic_mixed_precision = true

# Memory management
memory_pool = true
garbage_collection = true
memory_fragmentation_check = true

# Compute optimization
kernel_optimization = true
tensor_parallelism = false
pipeline_parallelism = false

[gpu.batching]
# Batch processing optimization
optimal_batch_size = 512
max_batch_size = 2048
min_batch_size = 32
dynamic_batching = true
batch_size_adaptation = true

# Memory-based batch sizing
memory_threshold_percent = 80
adaptive_batch_memory = true

[gpu.memory]
# Memory management strategies
preallocation = true
memory_pool_size_gb = 20
cleanup_threshold_percent = 85
emergency_cleanup_threshold_percent = 95

# Memory monitoring
enable_memory_monitoring = true
memory_logging_interval_seconds = 30
memory_warning_threshold_percent = 70

[gpu.performance]
# Performance monitoring and tuning
enable_profiling = false
profiling_interval_minutes = 60
performance_logging = true
benchmark_on_startup = true

# GPU utilization targets
target_utilization_percent = 85
max_utilization_percent = 95
thermal_threshold_celsius = 85

[gpu.fault_tolerance]
# Error handling and recovery
enable_watchdog = true
watchdog_interval_seconds = 60
max_retries = 3
retry_delay_seconds = 5

# Memory error handling
out_of_memory_handling = true
graceful_degradation = true
memory_error_recovery = true

[gpu.compatibility]
# Compatibility settings
cuda_version = "12.1"
cudnn_version = "8.9"
driver_version_min = "530.30.02"

# Framework compatibility
pytorch_compatibility = true
tensorflow_compatibility = true
rapids_compatibility = true

[gpu.advanced]
# Advanced optimization features
enable_xla = true
enable_cudnn_benchmark = true
enable_cudnn_deterministic = false
enable_tf32 = true

# Multi-GPU settings (for future expansion)
multi_gpu_support = false
data_parallelism = false
model_parallelism = false